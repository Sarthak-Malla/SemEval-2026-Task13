{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --upgrade transformers==4.45.0 huggingface_hub","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_DISABLED\"] = \"true\"\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom datasets import load_dataset, Dataset\nfrom transformers import (\n    RobertaTokenizer,\n    RobertaForSequenceClassification,\n    TrainingArguments,\n    Trainer,\n    EarlyStoppingCallback,\n    DataCollatorWithPadding\n)\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\nimport argparse\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We suggest using a single class, it will make refinement easier.\n\nIn your implementation, feel free to update the training procedure, change model and do whatever feels right\n\n","metadata":{}},{"cell_type":"code","source":"class CodeBERTTrainer:\n    def __init__(self, max_length=512, model_name=\"microsoft/codebert-base\"):\n        self.max_length = max_length\n        self.model_name = model_name\n        self.tokenizer = None\n        self.model = None\n        self.num_labels = None\n        \n    def load_and_prepare_data(self):\n        \n        try:\n            df = pd.read_parquet('/kaggle/input/sem-eval-2026-task-13-subtask-b/Task_B/train.parquet')\n            \n            print(f\"Dataset columns: {df.columns.tolist()}\")\n            print(f\"Sample data:\\n{df.head()}\")\n            \n            if 'code' not in df.columns or 'label' not in df.columns:\n                raise ValueError(\"Dataset must contain 'code' and 'label' columns\")\n            \n            df = df.dropna(subset=['code', 'label'])\n            \n            df['label'] = df['label'].astype(int)\n            self.num_labels = df['label'].nunique()\n            \n            print(f\"Number of unique labels: {self.num_labels}\")\n            print(f\"Label range: {df['label'].min()} to {df['label'].max()}\")\n            print(f\"Label distribution:\\n{df['label'].value_counts().sort_index()}\")\n\n            val_df = pd.read_parquet('/kaggle/input/sem-eval-2026-task-13-subtask-b/Task_B/validation.parquet')\n            \n            print(f\"Train samples: {len(df)}, Validation samples: {len(val_df)}\")\n            \n            return df, val_df\n            \n        except Exception as e:\n            print(f\"Error loading dataset: {e}\")\n            raise\n    \n    def initialize_model_and_tokenizer(self):\n        print(f\"Initializing {self.model_name} model and tokenizer...\")\n        \n        self.tokenizer = RobertaTokenizer.from_pretrained(self.model_name)\n        \n        self.model = RobertaForSequenceClassification.from_pretrained(\n            self.model_name,\n            num_labels=self.num_labels,\n            problem_type=\"single_label_classification\"\n        ).to('cuda')\n        \n        print(f\"Model initialized with {self.num_labels} labels\")\n    \n    def tokenize_function(self, examples):\n        return self.tokenizer(\n            examples['code'],\n            truncation=True,\n            padding=True,\n            max_length=self.max_length,\n            return_tensors=\"pt\"\n        )\n    \n    def prepare_datasets(self, train_df, val_df):\n        print(\"Preparing datasets for training...\")\n        \n        train_dataset = Dataset.from_pandas(train_df[['code', 'label']])\n        val_dataset = Dataset.from_pandas(val_df[['code', 'label']])\n        \n        train_dataset = train_dataset.map(\n            self.tokenize_function,\n            batched=True,\n            remove_columns=['code']\n        )\n        val_dataset = val_dataset.map(\n            self.tokenize_function,\n            batched=True,\n            remove_columns=['code']\n        )\n        \n        train_dataset = train_dataset.rename_column('label', 'labels')\n        val_dataset = val_dataset.rename_column('label', 'labels')\n        \n        return train_dataset, val_dataset\n    \n    def compute_metrics(self, eval_pred):\n        predictions, labels = eval_pred\n        predictions = np.argmax(predictions, axis=1)\n        \n        accuracy = accuracy_score(labels, predictions)\n        precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted')\n        \n        return {\n            'accuracy': accuracy,\n            'f1': f1,\n            'precision': precision,\n            'recall': recall\n        }\n    \n    def train(self, train_dataset, val_dataset, output_dir=\"./results\", num_epochs=3, batch_size=16, learning_rate=2e-5):\n        print(\"Starting training...\")\n        print(self.model)\n        print(self.model.device)\n        training_args = TrainingArguments(\n            output_dir=output_dir,\n            num_train_epochs=num_epochs,\n            per_device_train_batch_size=batch_size,\n            per_device_eval_batch_size=batch_size,\n            # warmup_steps=500,\n            weight_decay=0.01,\n            logging_dir='./logs',\n            logging_steps=5,\n            evaluation_strategy=\"steps\",\n            eval_steps=500,\n            save_strategy=\"steps\",\n            save_steps=500,\n            load_best_model_at_end=True,\n            metric_for_best_model=\"f1\",\n            greater_is_better=True,\n            remove_unused_columns=False,\n            learning_rate=learning_rate,\n            lr_scheduler_type=\"linear\",\n            save_total_limit=2,\n            report_to=[],\n        )\n        \n        data_collator = DataCollatorWithPadding(tokenizer=self.tokenizer)\n        \n        trainer = Trainer(\n            model=self.model,\n            args=training_args,\n            train_dataset=train_dataset,\n            eval_dataset=val_dataset,\n            tokenizer=self.tokenizer,\n            data_collator=data_collator,\n            compute_metrics=self.compute_metrics,\n            callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n        )\n        print(f\"Start training\")\n        trainer.train()\n        \n        trainer.save_model()\n        self.tokenizer.save_pretrained(output_dir)\n        \n        print(f\"Training completed. Model saved to {output_dir}\")\n        \n        return trainer\n    \n    def evaluate_model(self, trainer, val_dataset):\n        print(\"Evaluating model...\")\n        \n        predictions = trainer.predict(val_dataset)\n        y_pred = np.argmax(predictions.predictions, axis=1)\n        y_true = predictions.label_ids\n        \n        print(\"Classification Report:\")\n        print(classification_report(y_true, y_pred))\n        \n        return predictions\n    \n    def run_full_pipeline(self, output_dir=\"./results\", num_epochs=3, batch_size=16, learning_rate=2e-5):\n        try:\n            train_df, val_df = self.load_and_prepare_data()\n            \n            self.initialize_model_and_tokenizer()\n            \n            train_dataset, val_dataset = self.prepare_datasets(train_df, val_df)\n            \n            trainer = self.train(\n                train_dataset, val_dataset, \n                output_dir=output_dir,\n                num_epochs=num_epochs,\n                batch_size=batch_size,\n                learning_rate=learning_rate\n            )\n            \n            self.evaluate_model(trainer, val_dataset)\n            \n            print(\"Pipeline completed successfully!\")\n            return trainer\n            \n        except Exception as e:\n            print(f\"Error in pipeline: {e}\")\n            raise","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T05:23:30.288837Z","iopub.execute_input":"2025-10-29T05:23:30.289368Z","iopub.status.idle":"2025-10-29T05:23:30.304943Z","shell.execute_reply.started":"2025-10-29T05:23:30.289341Z","shell.execute_reply":"2025-10-29T05:23:30.304272Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"OUTPUT_DIR = \"taskB-model\"\n\ntrainer_obj = CodeBERTTrainer(\n    max_length=256, \n)\n\nt = trainer_obj.run_full_pipeline(\n    output_dir=OUTPUT_DIR,\n    num_epochs=10,\n    batch_size=16,\n    learning_rate=2e-5\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport logging\nfrom itertools import chain\nfrom datasets import load_dataset\nfrom tqdm import tqdm\n\n\n@torch.no_grad()\ndef predict_with_trainer(trainer_obj, parquet_path, output_path, max_length=512, batch_size=16, device=None):\n    \"\"\"\n    Uses trainer_obj.model and trainer_obj.tokenizer to run streaming inference\n    over a parquet file with columns ['ID','code'] and writes 'ID,prediction' CSV.\n    \"\"\"\n    if device is None:\n        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n    # Pull model & tokenizer from your trainer object\n    model = trainer_obj.model\n    tokenizer = trainer_obj.tokenizer if hasattr(trainer_obj, \"tokenizer\") else trainer_obj.args._setup_devices and None\n    if tokenizer is None and hasattr(trainer_obj, \"tokenizer\"):\n        tokenizer = trainer_obj.tokenizer\n    if tokenizer is None:\n        raise ValueError(\"trainer_obj must have a tokenizer (e.g., provided when creating the Trainer).\")\n\n    model.to(device)\n    model.eval()\n\n    # Stream parquet (no RAM blowup)\n    ds = load_dataset(\"parquet\", data_files=parquet_path, split=\"train\", streaming=True)\n\n    # Validate schema and re-chain the first row back into the stream\n    it = iter(ds)\n    first = next(it)\n    if not {\"ID\", \"code\"}.issubset(first.keys()):\n        raise ValueError(\"Parquet file must contain 'ID' and 'code' columns\")\n    stream = chain([first], it)\n\n    def batcher(iterator, bs):\n        buf = []\n        for ex in iterator:\n            buf.append(ex)\n            if len(buf) == bs:\n                yield buf\n                buf = []\n        if buf:\n            yield buf\n\n    with open(output_path, \"w\") as f:\n        f.write(\"ID,prediction\\n\")\n\n        for batch in tqdm(batcher(stream, batch_size), desc=\"Predicting\"):\n            codes = [row[\"code\"] for row in batch]\n            ids   = [row[\"ID\"] for row in batch]\n\n            enc = tokenizer(\n                codes,\n                truncation=True,\n                padding=True,\n                max_length=max_length,\n                return_tensors=\"pt\",\n            )\n            input_ids = enc[\"input_ids\"].to(device)\n            attention_mask = enc[\"attention_mask\"].to(device)\n\n            logits = model(input_ids=input_ids, attention_mask=attention_mask).logits\n            pred_labels = logits.argmax(dim=-1).cpu().tolist()\n\n            for ex_id, pred in zip(ids, pred_labels):\n                f.write(f\"{ex_id},{pred}\\n\")\n\n    print(f\"Predictions saved to {output_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T05:24:10.659995Z","iopub.execute_input":"2025-10-29T05:24:10.660286Z","iopub.status.idle":"2025-10-29T05:24:10.681645Z","shell.execute_reply.started":"2025-10-29T05:24:10.660263Z","shell.execute_reply":"2025-10-29T05:24:10.680909Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"TEST_PARQUET = \"/kaggle/input/sem-eval-2026-task-13-subtask-b/Task_B/test.parquet\"\nOUT_CSV = \"/kaggle/working/submission.csv\"\n\npredict_with_trainer(\n    trainer_obj=t,          \n    parquet_path=TEST_PARQUET,\n    output_path=OUT_CSV,\n    max_length=256,\n    batch_size=32,\n    device=\"cuda\"              \n)\n\nprint(\"Wrote:\", OUT_CSV)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T05:24:10.683660Z","iopub.execute_input":"2025-10-29T05:24:10.683916Z","iopub.status.idle":"2025-10-29T05:24:21.922320Z","shell.execute_reply.started":"2025-10-29T05:24:10.683894Z","shell.execute_reply":"2025-10-29T05:24:21.921598Z"}},"outputs":[{"name":"stderr","text":"Predicting: 32it [00:09,  3.26it/s]","output_type":"stream"},{"name":"stdout","text":"Predictions saved to /kaggle/working/submission.csv\nWrote: /kaggle/working/submission.csv\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}